{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#CMPT353 summer 2020\n",
    "#SFU\n",
    "#Course Project\n",
    "#Author: Wei Yao (yaoweiy@sfu.ca) Yiran Zhang (yza363@sfu.ca)\n",
    "#Dataset 1: Covid-19\n",
    "#Resource Ref: https://www.kaggle.com/kimjihoo/coronavirusdataset\n",
    "#Dataset 2: COVID19 Global Forecasting\n",
    "#Resource Ref: https://www.kaggle.com/c/covid19-global-forecasting-week-5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import plotly.express as px\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Cases vs Time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "time_count = pd.read_csv('Time.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "time_count.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "time_count.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#drop null if any and delete the unnecessary column ['time']\n",
    "time_count.dropna()\n",
    "time_count.drop(columns=['time'], inplace=True)\n",
    "time_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1. Total Cases vs Confirmed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(time_count.head())\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.xticks(rotation=25)\n",
    "plt.title('COVID-19 Confirmed Cases  VS time in 2020 ')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Number of Confirmed Cases')\n",
    "plt.plot(time_count['date'],time_count['confirmed'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The x-axis looks wried, so I tried to modify the data timestamp to give a clear view again\n",
    "seaborn.set()\n",
    "time_count['date']=pd.to_datetime(time_count['date'],format = '%Y-%m-%d')\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.xticks(rotation=25)\n",
    "plt.title('COVID-19 Confirmed Cases  VS Time in 2020 ')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Number of Confirmed Cases')\n",
    "plt.plot(time_count['date'],time_count['confirmed'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Add more details into the cases ( negative and total tested cases)\n",
    "time_count['percentage'] =time_count['confirmed'] / time_count['test']\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.xticks(rotation=25)\n",
    "plt.title('COVID-19 Confirmed Cases  VS time in 2020 ')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Number of Confirmed Cases')\n",
    "plt.plot(time_count['date'],time_count['test']/100,'r.')\n",
    "plt.plot(time_count['date'],time_count['negative']/100,'g.')\n",
    "plt.plot(time_count['date'],time_count['confirmed'],'b.')\n",
    "plt.legend(['Total Tested','Negative','Confirmed(Positive)'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2. Percentage Ratio of Confirmed Cases Trends"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#print(time_count)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.title('COVID-19 Confirmed Cases in Percentage  VS time in 2020 ')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Percentage of Positive/Total Tested')\n",
    "plt.plot(time_count['date'],time_count['percentage'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3. Comparison of New Cases"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "color_list = ['#8DD3C7', '#FEFFB3', '#BFBBD9'\n",
    "              , '#FA8174', '#81B1D2', '#FDB462'\n",
    "              , '#B3DE69', '#BC82BD', '#CCEBC4']\n",
    "\n",
    "def plot_lines(data, column_list, column_max, title):\n",
    "    \"\"\"\n",
    "    FUNCTION\n",
    "        to show many plots with combinations of lines with consistent colors and legend\n",
    "        useful for plotting lines with different scales at once and then separately\n",
    "\n",
    "    RETURN\n",
    "        None\n",
    "    \"\"\"\n",
    "    for i in column_list:\n",
    "        fig, ax = plt.subplots(figsize=(13, 7))\n",
    "        plt.title(f'{title}', fontsize=17)\n",
    "        color_group = color_list[:-4][-(column_max-i):]\n",
    "        for test_each, color_each in zip(data.columns[i:column_max], color_group):\n",
    "            plt.plot(data.date, data[test_each]\n",
    "                     , label=test_each, color=color_each\n",
    "                    )\n",
    "            label=data[test_each]\n",
    "        ax.set_xticks(ax.get_xticks()[::int(len(data.date)/8)])\n",
    "        plt.xlabel('Date', size=13)\n",
    "        plt.ylabel('Number of cases', size=13)\n",
    "        ax.legend(loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "for col in time_count.columns[2:7]:\n",
    "    if col in [2, 4]:\n",
    "        new_dict = {0: 1}\n",
    "    else:\n",
    "        new_dict = {0: 0}\n",
    "    new_dict.update({ i : time_count[col][i] - time_count[col][i-1] for i in range(1, len(time_count)) })\n",
    "    time_count[f'new_{col}'] = new_dict.values()\n",
    "\n",
    "plot_lines(time_count, [7],12, 'Cumulative Cases')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Case vs Age"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.read_csv('PatientInfo.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# clean data: drop null if any and select necessary column ['sex','age']\n",
    "data = data[data['country'] == 'Korea']\n",
    "data = data[['sex', 'age']]\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1. Male and Female Case vs Age"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "age_count = pd.DataFrame(data['age'].value_counts())\n",
    "age_count.reset_index(level=0, inplace = True)\n",
    "age_count.columns = ['age', 'counts']\n",
    "age_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def str_to_int(age):\n",
    "    for i in range(0,age.shape[0]):\n",
    "        age[i] = int(age[i][:-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set age as int\n",
    "str_to_int(age_count['age'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sort age from 0 to 100\n",
    "age_count = age_count.sort_values('age')\n",
    "age_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.xticks(rotation=25)\n",
    "plt.title('COVID-19 Confirmed Cases VS Age in 2020')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Number of Confirmed Cases')\n",
    "plt.plot(age_count['age'],age_count['counts'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2. Male Case vs Age"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "male_data = data[data['sex'] == 'male']\n",
    "male_age_count = pd.DataFrame(male_data['age'].value_counts())\n",
    "male_age_count.reset_index(level=0, inplace = True)\n",
    "male_age_count.columns = ['age', 'counts']\n",
    "male_age_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set age as int\n",
    "str_to_int(male_age_count['age'])\n",
    "# sort age from 0 to 90\n",
    "male_age_count = male_age_count.sort_values('age')\n",
    "male_age_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.xticks(rotation=25)\n",
    "plt.title('COVID-19 Confirmed Male Cases VS Age in 2020')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Number of Confirmed Cases')\n",
    "plt.plot(male_age_count['age'],male_age_count['counts'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3. Female Case vs Age"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "female_data = data[data['sex'] == 'female']\n",
    "female_age_count = pd.DataFrame(female_data['age'].value_counts())\n",
    "female_age_count.reset_index(level=0, inplace = True)\n",
    "female_age_count.columns = ['age', 'counts']\n",
    "female_age_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set age as int\n",
    "str_to_int(female_age_count['age'])\n",
    "# sort age from 0 to 100\n",
    "female_age_count = female_age_count.sort_values('age')\n",
    "female_age_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.xticks(rotation=25)\n",
    "plt.title('COVID-19 Confirmed Female Cases VS Age in 2020')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Number of Confirmed Cases')\n",
    "plt.plot(female_age_count['age'],female_age_count['counts'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.4. Merge Into One Diagram"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.xticks(rotation=25)\n",
    "plt.title('COVID-19 Confirmed Cases VS Age in 2020 ')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Number of Confirmed Cases')\n",
    "plt.plot(age_count['age'],age_count['counts'],'r')\n",
    "plt.plot(male_age_count['age'],male_age_count['counts'],'g')\n",
    "plt.plot(female_age_count['age'],female_age_count['counts'],'b')\n",
    "plt.legend(['Male & Female','Male','Female'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.5. The Proportion of Patients of All Ages was Compared"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sum the number of cases for three diff ways\n",
    "mf_case = age_count['counts'].sum()\n",
    "m_case = male_age_count['counts'].sum()\n",
    "f_case = female_age_count['counts'].sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# both male and female\n",
    "age_count['proportion'] = (age_count['counts'] / mf_case) * 100\n",
    "age_count['proportion'] = age_count['proportion'].round(decimals=2)\n",
    "# male\n",
    "male_age_count['proportion'] = (age_count['counts'] / mf_case) * 100\n",
    "male_age_count['proportion'] = age_count['proportion'].round(decimals=2)\n",
    "# female\n",
    "female_age_count['proportion'] = (age_count['counts'] / mf_case) * 100\n",
    "female_age_count['proportion'] = age_count['proportion'].round(decimals=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.xticks(rotation=25)\n",
    "plt.title('COVID-19 Proportion of Patients VS Age in 2020 (Line)')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('The Proportion of Patients')\n",
    "plt.plot(age_count['age'],age_count['proportion'],'r')\n",
    "plt.plot(male_age_count['age'],male_age_count['proportion'],'g--')\n",
    "plt.plot(female_age_count['age'],female_age_count['proportion'],'b-.')\n",
    "plt.legend(['Male & Female','Male','Female'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.xticks(rotation=25)\n",
    "plt.title('COVID-19 Proportion of Patients VS Age in 2020 (Dot)')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('The Proportion of Patients')\n",
    "plt.plot(age_count['age'],age_count['proportion'],'r.')\n",
    "plt.plot(male_age_count['age'],male_age_count['proportion'],'g.')\n",
    "plt.plot(female_age_count['age'],female_age_count['proportion'],'b.')\n",
    "plt.legend(['Male & Female','Male','Female'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Case vs City"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.read_csv('PatientInfo.csv')\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# clean data: drop null if any and select necessary column ['sex','age']\n",
    "data = data[data['country'] == 'Korea']\n",
    "data = data[['province','city']]\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1. Cases vs Province"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "province_count = pd.DataFrame(data['province'].value_counts())\n",
    "province_count.reset_index(level=0, inplace=True)\n",
    "province_count.columns = ['province', 'counts']\n",
    "province_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.pie(province_count, values='counts', names='province')\n",
    "fig.update_traces(textposition='inside')\n",
    "fig.update_layout(uniformtext_minsize=12, uniformtext_mode='hide')\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Cases vs City"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "city_count = pd.DataFrame(data['city'].value_counts())\n",
    "city_count.reset_index(level=0, inplace = True)\n",
    "city_count.columns = ['city', 'counts']\n",
    "city_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.pie(city_count, values='counts', names='city')\n",
    "fig.update_traces(textposition='inside')\n",
    "fig.update_layout(uniformtext_minsize=12, uniformtext_mode='hide')\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3 Merge City and Province"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "city_province = data.drop_duplicates(subset='city',keep='first', inplace=False).reset_index(drop=True)\n",
    "city_province = city_province[['province','city']]\n",
    "city_province"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Merge the two dfs based on city column\n",
    "city_count.set_index(['city'], inplace=True)\n",
    "result = city_province.join(city_count,on='city')\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.treemap(result, path=['province','city'], values='counts',\n",
    "                  color='counts', hover_data=['city'],\n",
    "                  color_continuous_scale='matter', title='Current COVID19 Confirmed Cases In South Korea')\n",
    "fig.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Prediction Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#load data\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#get the name of 'south korean'\n",
    "country =train_data.Country_Region.unique()\n",
    "print(country)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# filter to extract korean data\n",
    "train_data=train_data[train_data['Country_Region']=='Korea, South']\n",
    "\n",
    "# check head and drop unuseful columns\n",
    "train=train_data.drop(['Id','County','Province_State','Country_Region'],axis=1)\n",
    "\n",
    "# convert the target value to integer, confirmedCases to 1, Fatalities to 0\n",
    "train['Target'].replace({'ConfirmedCases':1, 'Fatalities':0}, inplace=True)\n",
    "\n",
    "train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# filter to extract korean data\n",
    "test_data=test_data[test_data['Country_Region']=='Korea, South']\n",
    "\n",
    "# check head and drop unuseful columns\n",
    "test=test_data.drop(['ForecastId','County','Province_State','Country_Region'],axis=1)\n",
    "\n",
    "# convert the target value to integer, confirmedCases to 1, Fatalities to 0\n",
    "test['Target'].replace({'ConfirmedCases':1, 'Fatalities':0}, inplace=True)\n",
    "\n",
    "test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create useful features for data mining tools to increase performance\n",
    "# By transforming 'Date' into single values such as 'day' 'dayofweek' 'month'...\n",
    "train['Date']=pd.to_datetime(train['Date'],format = '%Y-%m-%d')\n",
    "train['day']=train['Date'].dt.day\n",
    "train['month'] = train['Date'].dt.month\n",
    "train['quarter'] = train['Date'].dt.quarter\n",
    "train['dayofweek'] = train['Date'].dt.dayofweek\n",
    "train['dayofyear'] = train['Date'].dt.dayofyear\n",
    "train['weekofyear'] = train['Date'].dt.weekofyear\n",
    "train=train.drop(['Date'],axis=1)\n",
    "X=train.drop(['TargetValue'],axis=1)\n",
    "y=train['TargetValue']\n",
    "X.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# modify the features of test data also\n",
    "# perform the predict model with good score\n",
    "test['Date']=pd.to_datetime(test['Date'],format = '%Y-%m-%d')\n",
    "test['day']=test['Date'].dt.day\n",
    "test['month'] = test['Date'].dt.month\n",
    "test['quarter'] = test['Date'].dt.quarter\n",
    "test['dayofweek'] = test['Date'].dt.dayofweek\n",
    "test['dayofyear'] = test['Date'].dt.dayofyear\n",
    "test['weekofyear'] = test['Date'].dt.weekofyear\n",
    "test=test.drop(['Date'],axis=1)\n",
    "test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.1. The Model is Established and the Predicted Value is Output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.23)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# gradient_model = make_pipeline(\n",
    "#     GradientBoostingClassifier(n_estimators =70,max_depth=3, min_samples_leaf =1)\n",
    "# )\n",
    "# random_f_model = make_pipeline(\n",
    "#     RandomForestClassifier(n_estimators =200,max_depth =9, min_samples_leaf=40)\n",
    "# )\n",
    "# neural_net_model = make_pipeline(\n",
    "#     MLPClassifier(solver ='lbfgs',hidden_layer_sizes=(11,11),activation ='logistic')\n",
    "# )\n",
    "#\n",
    "# knn_model = make_pipeline(\n",
    "#         KNeighborsClassifier(n_neighbors=10)\n",
    "# )\n",
    "#\n",
    "# models = [gradient_model,random_f_model,neural_net_model,knn_model]\n",
    "#\n",
    "# for i, m in enumerate(models):\n",
    "#     m.fit(X_train, y_train)\n",
    "#     print(metrics.accuracy_score(y_test, m.predict(X_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# knn_model = make_pipeline(\n",
    "#         KNeighborsClassifier(n_neighbors=10)\n",
    "# )\n",
    "# knn_model.fit(X_train, y_train)\n",
    "# predictions = knn_model.predict(test)\n",
    "# pd.Series(predictions).to_csv('output.txt', index=False, header=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.2. Conduct k-fold Validation and Report Precision. Recall and Accuracy for Each Validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#split data\n",
    "kf =KFold(n_splits =10)\n",
    "\n",
    "#create pipeline\n",
    "dt_model = make_pipeline(\n",
    "    tree.DecisionTreeClassifier()\n",
    ")\n",
    "\n",
    "#train model\n",
    "#dt_model.fit(X_train,y_train)\n",
    "iteration = 1\n",
    "macro_precision =0\n",
    "macro_recall =0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    #split data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    #train data\n",
    "    dt_model.fit(X_train,y_train)\n",
    "    y_predicted = dt_model.predict(X_test)\n",
    "    print('Iteration #',iteration,':')\n",
    "    iteration += 1\n",
    "    print(classification_report(y_test,y_predicted))\n",
    "    report = classification_report(y_test,y_predicted,output_dict=True)\n",
    "    macro_precision += report['macro avg']['precision']\n",
    "    macro_recall += report['macro avg']['recall']\n",
    "\n",
    "    # print scores to check overfiting\n",
    "    print('*******************')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Insights from Policy\n",
    "\n",
    "## 5.1。 Distribution of policy types"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "policy_df = pd.read_csv('Policy.csv')\n",
    "df_type=policy_df['type'].tolist()\n",
    "len(df_type)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "policy_df['type'].value_counts(dropna=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "type_df = pd.DataFrame({'Policy': [15/61, 15/61 , 10/61,6/61,5/61,4/61,3/61,3/61]  } ,\n",
    "                  index=['Immigration', 'Education', 'Health','Technology','Social','Alert','Administrative','Transformation'])\n",
    "plot=type_df.plot.pie(y='Policy',figsize=(10,18))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5.2 Detailed Policy application Date"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pre-process\n",
    "policy_df.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_gov_policy=policy_df['gov_policy'].tolist()\n",
    "policy_df['gov_policy'].value_counts(dropna=True)\n",
    "# sort data by date\n",
    "\n",
    "policy_sort = policy_df.sort_values('start_date')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#replace long terms by short-cut\n",
    "policy_sort['gov_policy']=policy_sort['gov_policy'].map({'Special Immigration Procedure': 'SIP',\n",
    "                             'School Opening with Online Class':'SOOC',\n",
    "                             'Emergency Use Authorization of Diagnostic Kit':'WUA',\n",
    "                             'School Opening Delay':'SOD',\n",
    "                             'Social Distancing Campaign':'SDC',\n",
    "                             'Infectious Disease Alert Level':'IDAL',\n",
    "                             'Mask Distribution':'MD',\n",
    "                             'Wearing of masks':'WM',\n",
    "                             'Drive-Through Screening Center':'D-T',\n",
    "                             'Electronic Wristbands':'EW',\n",
    "                             'Self-Quarantine Safety Protection App':'S-Q',\n",
    "                             'Self-Diagnosis App':'S-D',\n",
    "                             'Open Data ':'OD',\n",
    "                             'Extends Tightened Quarantine Measures ':'ET',\n",
    "                             'Close bars and clubs':'CB',\n",
    "                             'School Closure':'SC',\n",
    "                             'Mandatory 14-day Self-Quarantine':'M14',\n",
    "                             'Open API':'OA',\n",
    "                             'Close karaoke':'CK',\n",
    "                             'Logistics center':'LC',\n",
    "                             'local government Administrative orders':'LG',\n",
    "                             'KI-Pass: Korea Internet - Pass':'KI',\n",
    "                             'Thanks to Challenge korea':'TC',\n",
    "                             'Mandatory Self-Quarantine & Diagonostic Tests':'MS'\n",
    "\n",
    "\n",
    "              })"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "policy_sort['gov_policy']\n",
    "#plt.plot(policy_df['gov_policy'],policy_df['start_date'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 17))\n",
    "plt.title('Policy start date ')\n",
    "plt.xlabel('Policy_name')\n",
    "plt.ylabel('Time')\n",
    "plt.scatter(policy_sort['gov_policy'],policy_sort['start_date'])\n",
    "plt.plot(policy_sort['gov_policy'],policy_sort['start_date'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. Seoul Floating"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('SeoulFloating.csv')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.dropna()\n",
    "df['date']=pd.to_datetime(df['date'],format = '%Y-%m-%d')\n",
    "df_male = df[df['sex']=='male']\n",
    "df_male.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.xticks(rotation=25)\n",
    "plt.title('Seoul_Floating Population ')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Population(millions)')\n",
    "plt.plot(df['date'],df['fp_num'],'r.')\n",
    "plt.plot(df_male['date'],df_male['fp_num'],'b.')\n",
    "plt.legend(['Male and Female','Male'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7. Tweet extracted with query COVID-19\n",
    "#      Analysis Token and pattern"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import collections\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import sys\n",
    "print(sys.executable)\n",
    "import re"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!/opt/anaconda3/bin/python -m pip install wordcloud"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7.1. Cleaning +Processing Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def helper factions to process extracted tweet file D2.txt\n",
    "# mainly focused on remove url + punctuation + stopwords+ other languages\n",
    "# split into list of words\n",
    "def remove_url_punctuation(x):\n",
    "    #get rid of url, punctuations, hashtags\n",
    "\n",
    "    url_pattern= re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    replace_url =url_pattern.sub(r'',str(x))\n",
    "    punctuation = re.compile(r'[^\\w\\s]')\n",
    "    without_punctuation = punctuation.sub(r'',replace_url).lower()\n",
    "    return without_punctuation\n",
    "\n",
    "def split(x):\n",
    "    #generate pieces of tokens from the entire text\n",
    "\n",
    "    split_word_list = x.split(\" \")\n",
    "    return split_word_list\n",
    "\n",
    "def remove_stopwords(x):\n",
    "    #remove stop words\n",
    "    global stop_words\n",
    "\n",
    "    without_stopwords = []\n",
    "    for word in x:\n",
    "        if word not in stop_words and len(word)>2 and word != 'nan':\n",
    "            without_stopwords.append(word)\n",
    "    return without_stopwords\n",
    "\n",
    "def detect_lang(x):\n",
    "    #extract english tweet only\n",
    "\n",
    "    from langdetect import detect\n",
    "    try:\n",
    "        lang = detect(x)\n",
    "        return(lang)\n",
    "    except:\n",
    "        return(\"other\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7.2. Load tweets file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# you may need to rename the extrexcted D2.txt file by your default setting\n",
    "# since it may not include extension .txt when its ouputed by tweet_extracter.py\n",
    "df2 = pd.read_csv('D2.txt', sep='\\t', names=['id','text'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7.3. Apply clearning functions to get tidy tweet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df2['tidy_tweet'] = df2['text'].apply(remove_url_punctuation)\n",
    "\n",
    "print(df2['text'].head())\n",
    "print(\"**********************\")\n",
    "print(df2['tidy_tweet'].head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 7.4. fliter  english only tweet\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!/opt/anaconda3/bin/python -m pip install langdetect\n",
    "df2['en']=df2['text'].apply(detect_lang)\n",
    "print(df2['tidy_tweet'].head(10))\n",
    "print(\"**********************\")\n",
    "df2 = df2[df2['en']=='en']\n",
    "print(df2['tidy_tweet'].head(10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7.5. Tokenize words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df2['word_list'] = df2['tidy_tweet'].apply(split)\n",
    "print(df2['word_list'].head(10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7.6. Remove Stop Words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "global stop_words\n",
    "stop_words =set(stopwords.words('english'))\n",
    "df2['nlp_tweet'] =df2['word_list'].apply(remove_stopwords)\n",
    "print(df2['word_list'].head(10))\n",
    "print(\"**********************\")\n",
    "print(df2['nlp_tweet'].head(10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7.7. Analysis Tokens (frequency)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#list of unique tokens\n",
    "all_words_unique_list2 = (df2['nlp_tweet'].explode()).unique()\n",
    "#num of unique tokens in D1\n",
    "print (len(all_words_unique_list2))\n",
    "word_list2 =list(df2['nlp_tweet'].explode())\n",
    "# use NLTK to create a dic of words with frenquency\n",
    "nltk_count2 = nltk.FreqDist(word_list2)\n",
    "print(nltk_count2.most_common(100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7.8. View as WordCloud"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wordcloud = WordCloud().generate_from_frequencies(nltk_count2)\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(wordcloud, interpolation  ='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 8. Glance at SearchTrends of South Korean"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "st_df = pd.read_csv('SearchTrend.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "st_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def range_of_date(df, date_col):\n",
    "    data_col = pd.to_datetime(df[date_col]).dt.date\n",
    "    date_range = (max(data_col) - min(data_col)).days + 1\n",
    "    print(f'# {min(data_col)} to {max(data_col)}')\n",
    "\n",
    "range_of_date(st_df,'date')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn\n",
    "seaborn.set()\n",
    "st_df['date']=pd.to_datetime(st_df['date'],format = '%Y-%m-%d')\n",
    "\n",
    "plt.figure(figsize=(12, 70))\n",
    "plt.xticks(rotation=25)\n",
    "plt.title('Search Trends of Cold/flu/pneumonia/coronavirus ')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Ratio')\n",
    "\n",
    "plt.plot(st_df['date'],st_df['cold'],'r.')\n",
    "plt.plot(st_df['date'],st_df['flu'],'b.')\n",
    "plt.plot(st_df['date'],st_df['pneumonia'],'g.')\n",
    "plt.plot(st_df['date'],st_df['coronavirus'],'y.')\n",
    "\n",
    "\n",
    "plt.legend(['cold','flu','pneumonia','coronavious'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#As expected, there were only the spikes of seasonal flu and cold before COVID-19 outbreak\n",
    "\n",
    "#Increase of searching pneumonia was prior to that of coronavirus(COVID-19)\n",
    "    #- because it's called Wuhan pneumonia at first in S.Korea\n",
    "      #  - Wuhan is the assumed place where COVID-19 pandemic started"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# After 1st case in korean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "after_first_case_df = st_df[st_df.date >= '2020-01-20']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 70))\n",
    "plt.xticks(rotation=25)\n",
    "plt.title('Search Trends of Cold/flu/pneumonia/coronavirus ')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Ratio')\n",
    "\n",
    "plt.plot(after_first_case_df['date'],after_first_case_df['cold'],'r.')\n",
    "plt.plot(after_first_case_df['date'],after_first_case_df['flu'],'b.')\n",
    "plt.plot(after_first_case_df['date'],after_first_case_df['pneumonia'],'g.')\n",
    "plt.plot(after_first_case_df['date'],after_first_case_df['coronavirus'],'y.')\n",
    "\n",
    "\n",
    "plt.legend(['cold','flu','pneumonia','coronavious'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dd= pd.read_csv('train.csv')\n",
    "dd.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-7cc73c60",
   "language": "python",
   "display_name": "PyCharm (cmpt353finalproject)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}